{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":113155,"databundleVersionId":13473948,"sourceType":"competition"},{"sourceId":13248875,"sourceType":"datasetVersion","datasetId":8364474},{"sourceId":590904,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":439753,"modelId":456306}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/adityakumarsingh135/melting-point-prediction?scriptVersionId=266578887\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:44:12.59631Z","iopub.execute_input":"2025-10-08T12:44:12.596625Z","iopub.status.idle":"2025-10-08T12:44:13.41938Z","shell.execute_reply.started":"2025-10-08T12:44:12.596602Z","shell.execute_reply":"2025-10-08T12:44:13.418537Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"RDkit is an open source cheminformatics library - basically a toolkit that helps scientists and devloper work with chemical structures using code ","metadata":{}},{"cell_type":"code","source":"!pip install rdkit ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:44:13.420219Z","iopub.execute_input":"2025-10-08T12:44:13.42057Z","iopub.status.idle":"2025-10-08T12:44:19.985871Z","shell.execute_reply.started":"2025-10-08T12:44:13.42054Z","shell.execute_reply":"2025-10-08T12:44:19.984959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil \nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt \n\nimport optuna \nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.preprocessing import PowerTransformer # data transformation technique that makes your data more gaussian forma or normal form \n# which often helps to imporve the accuracy \nfrom sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\nfrom sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors, Crippen, rdMolDescriptors, MACCSkeys, RDKFingerprint, rdFingerprintGenerator \nfrom rdkit.Chem.AtomPairs import Pairs, Torsions\n\nfrom rdkit import RDLogger\nRDLogger.DisableLog('rdApp.*')\n\ntry:\n    from rdkit.Avalon import pyAvalonTools\n    avalon_available = True\nexcept ImportError:\n    avalon_available = False\n\nimport plotly.io as pio\npio.renderers.default = \"iframe_connected\"\n\nfrom IPython.display import clear_output\n\nimport xgboost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:44:19.988334Z","iopub.execute_input":"2025-10-08T12:44:19.988556Z","iopub.status.idle":"2025-10-08T12:44:23.459761Z","shell.execute_reply.started":"2025-10-08T12:44:19.988537Z","shell.execute_reply":"2025-10-08T12:44:23.459116Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"chem give you access to molecular representation mol=Chem.molFromSmiles(\"cco\") ethanol. descriptors functions to calculate the physiochemical properties of molecules. crippen-> computes crippen descriptors , mailyLogP(octanol-water partition coefficient) and molecular Refractivity(MR) . MACCSKeys-> generates maccskeys fingerprints : a classic type of binary molecular fingerprint (166but vector) each bit represnts the presence /absemce of a predefined substructers . rdmodeldescriptors-> a collection of high level of molecular descriptions including morgan Fingerprints, topological torsion fingerprints, atom pair fingerprints.rdmolops/rdkfingerprint-> rdkfingerprint i sthe original rdkit fingerprint algorithm ","metadata":{}},{"cell_type":"code","source":"# loading the data \ntrain = pd.read_csv('/kaggle/input/melting-point/train.csv') \ntest = pd.read_csv('/kaggle/input/melting-point/test.csv')\n\nbradley = pd.read_excel('/kaggle/input/melting-point-chemical-dataset/BradleyMeltingPointDataset.xlsx')\nbradleyplus = pd.read_excel('/kaggle/input/melting-point-chemical-dataset/BradleyDoublePlusGoodMeltingPointDataset.xlsx')\n\n# hum log jo hamara competition ka data hai usme se compound and unka melting point rakh lenge and us particular compound\n# se related features hum rdkit ke through extract karenge \ntrain = train[['SMILES', 'Tm']]\ntest = test[['id', 'SMILES']]\n\ntrain.shape, test.shape, bradley.shape, bradleyplus.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:44:23.460372Z","iopub.execute_input":"2025-10-08T12:44:23.46057Z","iopub.status.idle":"2025-10-08T12:44:27.219042Z","shell.execute_reply.started":"2025-10-08T12:44:23.460554Z","shell.execute_reply":"2025-10-08T12:44:27.218402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bradley.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:44:27.219775Z","iopub.execute_input":"2025-10-08T12:44:27.220142Z","iopub.status.idle":"2025-10-08T12:44:27.240583Z","shell.execute_reply.started":"2025-10-08T12:44:27.220122Z","shell.execute_reply":"2025-10-08T12:44:27.239807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# tm clesius me diya ha we will convert it into kelvin \n# to convert it into kelvin \nbradley['Tm'] = bradley['mpC'].map(lambda x : x + 273.15)\n# same with bradleyplus \nbradleyplus['Tm'] = bradleyplus['mpC'].map(lambda x : x + 273.15)\n\n# hum sirf smiles and unka tm rakh rahe hai \nbradley = bradley[['smiles', 'Tm']]\nbradleyplus = bradleyplus[['smiles', 'Tm']]\n\nbradley_df = pd.concat((bradley, bradleyplus), axis = 0)\nbradley_df = bradley_df.rename(columns = {'smiles': 'SMILES'})\n\nbradley_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:44:27.241398Z","iopub.execute_input":"2025-10-08T12:44:27.24165Z","iopub.status.idle":"2025-10-08T12:44:27.263268Z","shell.execute_reply.started":"2025-10-08T12:44:27.241633Z","shell.execute_reply":"2025-10-08T12:44:27.26252Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# we will merge the bradley data and train data together \n\nmerge = pd.concat((train ,bradley_df), axis = 0)\n\nmerge ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:44:27.264001Z","iopub.execute_input":"2025-10-08T12:44:27.264316Z","iopub.status.idle":"2025-10-08T12:44:27.278696Z","shell.execute_reply.started":"2025-10-08T12:44:27.264298Z","shell.execute_reply":"2025-10-08T12:44:27.277955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# there are chances that the final dataset merge can have duplicate valeus so remove thpse\nmerge  = merge.drop_duplicates(subset = ['SMILES', 'Tm']).reset_index(drop = True)\n\nmerge\n\ndisplay(f\"{merge.duplicated(subset = ['SMILES', 'Tm']).sum()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:44:27.279539Z","iopub.execute_input":"2025-10-08T12:44:27.280333Z","iopub.status.idle":"2025-10-08T12:44:27.307894Z","shell.execute_reply.started":"2025-10-08T12:44:27.280309Z","shell.execute_reply":"2025-10-08T12:44:27.307349Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"pehle hume smajhna hoga ki secriptor_list dikhta kaisa hai , list where each item is a pair (a tuple) containing; -> a descriptor name , -> the function that calls it . (for name , func in descriptor_list) -> iterates through this list har step pe it unpacks one of the pairs, in first loop name will be molwt and function will be the molwt function , in second loop name will be 'numhdonors' and func will be the numhdonors and so on. \nname: this becomes the key in the new dictionary funct(mol) it calls the function that was just unpacked and passes your mol to it, the result becomes the value {..} the curly braces tell python to collect all these generated keys-value pairs and put them together into a single new dictionary .","metadata":{}},{"cell_type":"code","source":"def extract_all_descriptors(df, SMILES):\n    descriptor_list = Descriptors.descList \n    # Descriptors.descList -> contain all descriptors names and function\n    descriptors = [desc[0] for desc in descriptor_list]\n\n\n    result = []\n    for smi in df[SMILES]:\n        mol = Chem.MolFromSmiles(smi)\n\n        if mol is None:\n            row = {name: None for name , func in descriptor_list}\n        else:\n            row = {name: func(mol) for name , func in descriptor_list}\n            result.append(row)\n\n    df_descriptor = pd.DataFrame(result) # converting into a dataset \n    df_result = pd.concat((df, df_descriptor), axis = 1)\n\n    return df_result\n\nmerge = extract_all_descriptors(merge, 'SMILES')\n\ntest = extract_all_descriptors(test, 'SMILES')\n\nmerge = merge.dropna().reset_index(drop = True)\ntest = test.dropna().reset_index(drop = True)\n\nmerge\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:44:27.309683Z","iopub.execute_input":"2025-10-08T12:44:27.309912Z","iopub.status.idle":"2025-10-08T12:47:21.893448Z","shell.execute_reply.started":"2025-10-08T12:44:27.309899Z","shell.execute_reply":"2025-10-08T12:47:21.892578Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # we have extracted the descriptors features and now its time to extarct the molecular fingerprint features \n# def extract_all_fingerprints(df, SMILES, morgan_radius = 2 , morgan_nbits = 1024 ):\n#     fps_data = []\n\n#     morgan_gen = rdFingerprintGenerator.GetMorganGenerator(radius = morgan_radius, fpSize = morgan_nbits, countSimulation = True, includeChirality = False)\n#     fcfp = rdFingerprintGenerator.GetMorganFeatureAtomInvGen()\n#     fcfp_gen = rdFingerprintGenerator.GetMorganGenerator(radius = morgan_nbits, fpSize = morgan_nbits, atomInvariantsGenerator = fcfp, countSimulation= True, includeChirality = False)\n\n#     atom_gen = rdFingerprintGenerator.GetAtomPairGenerator(fpSize = 2048, countSimulation= True, includeChirality = False)\n\n#     # iterate every sample of smiles features\n                                                           \n#     for smiles in df[SMILES]:\n#         mol = Chem.MolFromSmiles(smiles)\n\n#         if mol is None:\n#             print(smiles, 'is invalid !')\n#             fps_data.append({})\n#             continue\n\n#         feature_rows = {}\n\n#         morgan_fp = morgan_gen.GetFingerprint(mol)\n#         for i in range(morgan_nbits):\n#             feature_rows[f\"Morgan_{i}\"] = morgan_fp[i]\n\n#         maccs_fp = MACCSkeys.GenMACCSKeys(mol)\n#         for i in range(len(maccs_fp)):\n#             feature_rows[f\"MACCS_{i}\"] = int(maccs_fp[i])\n\n#         atompair_fp = atom_gen.GetCountFingerprint(mol)\n#         for i in range(morgan_nbits):\n#             feature_rows[f\"AtomPair_{i}\"] = atompair_fp[i]\n\n#         # RDKIT FINGERPRINT\n#         rdkit_fp = RDKFingerprint(mol)\n#         for i in range(len(rdkit_fp)):\n#             feature_rows[f\"RDKIT_{i}\"] = int(rdkit_fp[i])\n\n#         fps_data.append(feature_rows)\n\n#     print(f'There are {morgan_nbits} Morgan Fingerprint Features')\n#     print(f'There are {len(maccs_fp)} MACCS Keys Features')\n#     print(f'There are {len(rdkit_fp)} RDKIT Fingerprint Features')\n    \n#     fps_df = pd.DataFrame(fps_data)\n#     df_result = pd.concat((df, fps_data), axis = 1)\n\n#     return df_result \n\n\n# merge = extract_all_fingerprints(merge, 'SMILES')\n# test = extract_all_fingerprints(test, 'SMILES')\n\n# merge","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:47:21.894382Z","iopub.execute_input":"2025-10-08T12:47:21.894913Z","iopub.status.idle":"2025-10-08T12:47:21.899007Z","shell.execute_reply.started":"2025-10-08T12:47:21.894888Z","shell.execute_reply":"2025-10-08T12:47:21.898342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_all_fingerprint(df, SMILES, morgan_radius = 2, morgan_nbits = 1024):\n\n    fps_data = []  # --> STORE NEW FEATURES DATA\n\n    # DEFINE MORGAN GENERATOR\n    morgan_gen = rdFingerprintGenerator.GetMorganGenerator(radius = morgan_radius, fpSize = morgan_nbits, countSimulation = True, includeChirality = False)\n\n    fcfp = rdFingerprintGenerator.GetMorganFeatureAtomInvGen()\n    fcfp_gen = rdFingerprintGenerator.GetMorganGenerator(radius = morgan_nbits, fpSize = morgan_nbits, atomInvariantsGenerator = fcfp, countSimulation= True, includeChirality = False)\n\n    atom_gen = rdFingerprintGenerator.GetAtomPairGenerator(fpSize = 2048, countSimulation= True, includeChirality = False)\n\n    # ITERATE EVERY SAMPLE OF SMILES FEATURES\n    for smiles in df[SMILES]:\n        mol = Chem.MolFromSmiles(smiles)\n\n        if mol is None:\n            print(smiles, 'is Invalid!')\n            fps_data.append({})\n            continue\n\n        # STORE NEW FEATURE FOR EACH SAMPLES CREATED\n        feature_rows = {}\n\n        # MORGAN FINGERPRINT (ECFP)\n        morgan_fp = morgan_gen.GetFingerprint(mol)\n        for i in range(morgan_nbits):\n            feature_rows[f\"Morgan_{i}\"] = morgan_fp[i]\n\n        # FUNCTIONAL-CLASS FINGERPRINT (FCFP)\n        fc_fp = fcfp_gen.GetFingerprint(mol)\n        for i in range(morgan_nbits):\n            feature_rows[f\"FCFP_{i}\"] = fc_fp[i]\n\n        # MACCS KEYS (166 BITS)\n        maccs_fp = MACCSkeys.GenMACCSKeys(mol)\n        for i in range(len(maccs_fp)):\n            feature_rows[f\"MACCS_{i}\"] = int(maccs_fp[i])\n\n       \n\n        # RDKIT FINGERPRINT\n        rdkit_fp = RDKFingerprint(mol)\n        for i in range(len(rdkit_fp)):\n            feature_rows[f\"RDKIT_{i}\"] = int(rdkit_fp[i])\n\n       \n\n\n        fps_data.append(feature_rows)\n\n    print(f'There are {morgan_nbits} Morgan Fingerprint Features')\n    print(f'There are {len(maccs_fp)} MACCS Keys Features')\n    print(f'There are {len(rdkit_fp)} RDKIT Fingerprint Features')\n\n    # MERGE REAL DATA WITH EXTRACTED FEATURES\n    fps_df = pd.DataFrame(fps_data)\n    df_result = pd.concat((df, fps_df), axis = 1)\n\n    return df_result\n\n\n# APPLY FUNCTION\nmerge = extract_all_fingerprint(merge, 'SMILES')\ntest  = extract_all_fingerprint(test, 'SMILES')\n\nmerge","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:47:21.899721Z","iopub.execute_input":"2025-10-08T12:47:21.899968Z","iopub.status.idle":"2025-10-08T12:49:51.003574Z","shell.execute_reply.started":"2025-10-08T12:47:21.899946Z","shell.execute_reply":"2025-10-08T12:49:51.002206Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**A molecular fingerprint is a way to represent a complex chemical structure as a simple list of numbers (a vector), making it easy for a computer to search, compare, and build machine learning models.** Using a generator is the modern and efficient way to do this in RDKit. Instead of re-typing the settings for every molecule, you create one generator object that holds your \"recipe\" for making fingerprints. This ensures consistency and is faster when you're processing a large dataset.\n****There are 1024 Morgan Fingerprint Features\nThere are 167 MACCS Keys Features\nThere are 2048 RDKIT Fingerprint Features****","metadata":{}},{"cell_type":"code","source":"# splitting the training and testing data \nx  = merge.drop(labels = ['SMILES', 'Tm'], axis = 1)\n\ny = merge['Tm']\n\nx_test = test.drop(labels = ['SMILES', 'id'], axis = 1)\n\nx.shape, y.shape, x_test.shape, type(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:49:51.004631Z","iopub.execute_input":"2025-10-08T12:49:51.004852Z","iopub.status.idle":"2025-10-08T12:49:51.225537Z","shell.execute_reply.started":"2025-10-08T12:49:51.004836Z","shell.execute_reply":"2025-10-08T12:49:51.224788Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"-> verbosity: 0 - controls the amount of logging XGBoost does\n-> objective - defines the type of problem(what the learns to minimize).\n'reg:squarederror'- minimizes mean squared error, 'reg:pseudohubererror- a robust loss'\n->tree-method - gpu_hist -> uses gpu for histogram-based tree building \n->predictor- ensures predictions run on GPU \n-> devices: cuda \n-> booster: 'gbtree' - defines the type of base model XGbost uses\n","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    xgb_params = {\n        \"verbosity\": 0, \n        \"objective\": trial.suggest_categorical(\"objective\", ['reg:squarederror', 'reg:pseudohubererror']),\n        \"tree_method\": \"gpu_hist\",\n        'predictor' : 'gpu_predictor',\n        'device' : 'cuda',\n        \"eval_metric\": \"rmse\",\n        \"booster\": \"gbtree\",\n        'n_estimators' : 10_000,\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 3e-3, 0.3, log=True),\n        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n        \"lambda\": trial.suggest_float(\"lambda\", 0.1, 20.0, log=True),\n        \"alpha\": trial.suggest_float(\"alpha\", 0.1, 20.0, log=True),\n    }\n\n\n    kfold = KFold(n_splits= 5 , shuffle =True, random_state = 2000)\n    rmse_scores = []\n\n    for train_idx, valid_idx in kf.split(x):\n        X_train , X_valid = x.iloc[train_idx], x.iloc[valid_idx]\n        y_train, y_valid = y[train_idx], y[valid_idx]\n\n\n        dtrain = xgboost.DMatrix(X_train, label = y_train)\n        dvalid = xgboost.DMatrix(X_valid, label = y_valid)\n\n        model = xgboost.train(\n            xgb_params,\n            dtrain, \n            num_boost_round = 10000,\n            evals= [(dvalid, \"validation\")],\n            early_stopping_rounds = 100,\n            verbose_eval = False,\n        )\n        pred = model.predict(dvalid)\n        rmse = mean_squared_error(y_valid, pred, squared =False)\n        rmse_scores.appen(rmse)\n\n    return np.mean(rmse_scores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:49:51.226411Z","iopub.execute_input":"2025-10-08T12:49:51.226646Z","iopub.status.idle":"2025-10-08T12:49:51.234585Z","shell.execute_reply.started":"2025-10-08T12:49:51.226628Z","shell.execute_reply":"2025-10-08T12:49:51.233526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# start optuna to finding the best parameters for our models \nshutil.copy(src = '/kaggle/input/optuna-study-3-models/other/optuna-study-3-models/3/xgb_study.db', dst = '/kaggle/working/xgb_study.db')\nstudy = optuna.create_study(direction = \"minimize\", study_name = 'xgb_study', storage=\"sqlite://////kaggle/working/xgb_study.db\", load_if_exists = True)\n\nclear_output(wait=True)\n\nprint(f'Training Complete! Congrats!')\nprint(f'Total Number of Trials : {len(study.trials)}\\n')\n\nprint(\"Best Trial\", study.best_trial.number)\nprint(\"Best MAE:\", study.best_value)\nprint(\"Best Params:\", study.best_trial.params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:49:51.235533Z","iopub.execute_input":"2025-10-08T12:49:51.235792Z","iopub.status.idle":"2025-10-08T12:49:52.85226Z","shell.execute_reply.started":"2025-10-08T12:49:51.235768Z","shell.execute_reply":"2025-10-08T12:49:52.851505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_params = {\n    'max_depth' : 6,\n    'eta' : 0.1,\n    'tree_method' : 'hist',\n    'eval_metric' : 'mae'\n}\n\nbest_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:49:52.853025Z","iopub.execute_input":"2025-10-08T12:49:52.853274Z","iopub.status.idle":"2025-10-08T12:49:52.858314Z","shell.execute_reply.started":"2025-10-08T12:49:52.853258Z","shell.execute_reply":"2025-10-08T12:49:52.857427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''{'objective': 'reg:squarederror',\n 'max_depth': 3,\n 'learning_rate': 0.01688021212211354,\n 'min_child_weight': 5,\n 'subsample': 0.8943127227676447,\n 'colsample_bytree': 0.590582609011384,\n 'gamma': 0.01132850232872052,\n 'lambda': 4.445806747037075,\n 'alpha': 0.1292033669407927,\n 'eval_metric': 'mae',\n 'device': 'cpu'}'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:49:52.859014Z","iopub.execute_input":"2025-10-08T12:49:52.859309Z","iopub.status.idle":"2025-10-08T12:49:52.874435Z","shell.execute_reply.started":"2025-10-08T12:49:52.859293Z","shell.execute_reply":"2025-10-08T12:49:52.873828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_params.update({\n    'n_estimators': 10_000,\n    'tree_method': 'gpu_hist',\n    'predictor': 'gpu_predictor',\n    'device': 'cuda',\n    'eval_metric': 'mae'  # since your best metric was MAE\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:49:52.875118Z","iopub.execute_input":"2025-10-08T12:49:52.875427Z","iopub.status.idle":"2025-10-08T12:49:52.887217Z","shell.execute_reply.started":"2025-10-08T12:49:52.875407Z","shell.execute_reply":"2025-10-08T12:49:52.886573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = merge.drop(columns=['SMILES', 'Tm'])\ny_train = merge['Tm']\nX_test = test.drop(columns=['SMILES'], errors='ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:49:52.888153Z","iopub.execute_input":"2025-10-08T12:49:52.888394Z","iopub.status.idle":"2025-10-08T12:49:53.190689Z","shell.execute_reply.started":"2025-10-08T12:49:52.888364Z","shell.execute_reply":"2025-10-08T12:49:53.190096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import xgboost as xgb\nfinal_model = xgb.XGBRegressor(**best_params)\n\nfinal_model.fit(\n    X_train, y_train,\n    eval_set=[(X_train, y_train)],\n    verbose=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T12:49:53.191363Z","iopub.execute_input":"2025-10-08T12:49:53.191537Z","iopub.status.idle":"2025-10-08T12:57:22.223711Z","shell.execute_reply.started":"2025-10-08T12:49:53.191523Z","shell.execute_reply":"2025-10-08T12:57:22.223042Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T13:01:16.122202Z","iopub.execute_input":"2025-10-08T13:01:16.122942Z","iopub.status.idle":"2025-10-08T13:01:16.127181Z","shell.execute_reply.started":"2025-10-08T13:01:16.12292Z","shell.execute_reply":"2025-10-08T13:01:16.126621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test = X_test.drop(columns = ['id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T13:01:48.223234Z","iopub.execute_input":"2025-10-08T13:01:48.223508Z","iopub.status.idle":"2025-10-08T13:01:48.232782Z","shell.execute_reply.started":"2025-10-08T13:01:48.223487Z","shell.execute_reply":"2025-10-08T13:01:48.231953Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = final_model.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T13:01:50.065587Z","iopub.execute_input":"2025-10-08T13:01:50.066297Z","iopub.status.idle":"2025-10-08T13:01:50.628866Z","shell.execute_reply.started":"2025-10-08T13:01:50.066272Z","shell.execute_reply":"2025-10-08T13:01:50.628329Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/melting-point/sample_submission.csv')\nsample.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T13:05:38.829979Z","iopub.execute_input":"2025-10-08T13:05:38.830567Z","iopub.status.idle":"2025-10-08T13:05:38.843596Z","shell.execute_reply.started":"2025-10-08T13:05:38.830543Z","shell.execute_reply":"2025-10-08T13:05:38.842864Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"assert len(sample) == len(y_pred)\n\nsubmission = pd.DataFrame({\n    'id': sample['id'],   # match Kaggle's expected order\n    'Tm': y_pred          # predicted target\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T13:09:48.416737Z","iopub.execute_input":"2025-10-08T13:09:48.417243Z","iopub.status.idle":"2025-10-08T13:09:48.422555Z","shell.execute_reply.started":"2025-10-08T13:09:48.41722Z","shell.execute_reply":"2025-10-08T13:09:48.421758Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.to_csv('submission1234.csv', index=False)\nprint(\"âœ… submission.csv created successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-08T13:09:54.829892Z","iopub.execute_input":"2025-10-08T13:09:54.830575Z","iopub.status.idle":"2025-10-08T13:09:54.836826Z","shell.execute_reply.started":"2025-10-08T13:09:54.830552Z","shell.execute_reply":"2025-10-08T13:09:54.836103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}